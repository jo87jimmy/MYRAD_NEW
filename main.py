import torch  # å¼•å…¥ PyTorch
from torchvision.datasets import ImageFolder  # ç”¨æ–¼å½±åƒè³‡æ–™å¤¾çš„è³‡æ–™é›†
import numpy as np  # æ•¸å€¼è¨ˆç®—å¥—ä»¶
import random  # äº‚æ•¸æ§åˆ¶
import os  # æª”æ¡ˆç³»çµ±æ“ä½œ
from torch.utils.data import DataLoader  # PyTorch çš„è³‡æ–™è¼‰å…¥å™¨
import torch.backends.cudnn as cudnn  # CUDA cuDNN åŠ é€Ÿ
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
from torch.nn import functional as F  # å¼•å…¥ PyTorch çš„å‡½å¼ä»‹é¢

from torch import optim
# æ–°å¢ç†±åŠ›åœ–å¯è¦–åŒ–æ‰€éœ€çš„å‡½å¼åº«
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
import cv2  # åŒ¯å…¥ OpenCVï¼Œç”¨æ–¼å½±åƒè™•ç†

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter

from model_unet import ReconstructiveSubNetwork
from student_models import StudentReconstructiveSubNetwork
import torchvision.utils as vutils

def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹

# === 3. ç‰¹å¾µæå– Hook ===
def get_embeddings(model, x):
    feats = []
    hooks = []

    def hook_fn(_, __, output):
        feats.append(output)

    for layer in model.modules():
        if isinstance(layer, nn.Conv2d):
            hooks.append(layer.register_forward_hook(hook_fn))

    _ = model(x)

    for h in hooks:
        h.remove()

    return feats
# RD4AD Loss (Cosine Similarity)
def rd4ad_loss(teacher_feats, student_feats,cos=None):
    loss = 0
    for t, s in zip(teacher_feats, student_feats):
        # normalize to unit length
        t = nn.functional.normalize(t.flatten(1), dim=1)
        s = nn.functional.normalize(s.flatten(1), dim=1)
        loss += torch.mean(1 - cos(t, s))
    return loss

def train(_arch_, _class_, epochs, save_pth_path):
    # è¨“ç·´æµç¨‹ä¸»å‡½æ•¸
    print(f"ğŸ”§ é¡åˆ¥: {_class_} | Epochs: {epochs}")

    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # é¸æ“‡é‹ç®—è£ç½®
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}")
    # === 1. è¼‰å…¥ Teacher (DRAEM è¨“ç·´å¥½çš„æ¨¡å‹) ===
    # æ•™å¸«æ¨¡å‹ (å·²è¼‰å…¥æ¬Šé‡ä¸¦è¨­ç‚º eval æ¨¡å¼)
    teacher_model = ReconstructiveSubNetwork(in_channels=3,
                                             out_channels=3)  # é‡å»ºå­ç¶²è·¯

    # === Step 2: è¼‰å…¥ checkpoint ===
    teacher_model_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle_.pckl",
        map_location=device,
        weights_only=True)  # è¼‰å…¥æ•™å¸«é‡å»ºæ¨¡å‹æ¬Šé‡

    teacher_model.load_state_dict(teacher_model_ckpt)  # å°‡æ¬Šé‡åŠ è¼‰åˆ°æ¨¡å‹

    # é‡è¦ï¼šè¼‰å…¥æ¬Šé‡å¾Œå†ç§»åˆ°è¨­å‚™
    teacher_model = teacher_model.to(device)
    teacher_model.eval()  # è¨­ç‚ºè©•ä¼°æ¨¡å¼ï¼Œä¸æ›´æ–°æ¬Šé‡
    for p in teacher_model.parameters():
        p.requires_grad = False

    # å­¸ç”Ÿæ¨¡å‹
    student_dropout_rate = 0.2  # Dropout ç‡ï¼Œå¯èª¿æ•´
    student_model = StudentReconstructiveSubNetwork(
        in_channels=3, out_channels=3,
        dropout_rate=student_dropout_rate)  # å­¸ç”Ÿé‡å»ºæ¨¡å‹

    # === 4. RD4AD Loss (Cosine Similarity) ===
    cos = nn.CosineSimilarity(dim=1)


    # === 5. Optimizer ===
    optimizer = optim.Adam(student_model.parameters(), lr=1e-4)

    # === 6. TensorBoard ===
    writer = SummaryWriter(log_dir="./runs/rd4ad")

    # === 7. è¨“ç·´ & é©—è­‰æµç¨‹ ===
    def anomaly_map(img):
        with torch.no_grad():
            t_feats = get_embeddings(teacher_model, img)
            s_feats = get_embeddings(student_model, img)

        score_maps = []
        for t, s in zip(t_feats, s_feats):
            t = nn.functional.normalize(t, dim=1)
            s = nn.functional.normalize(s, dim=1)
            diff = 1 - torch.mean(t * s, dim=1, keepdim=True)  # (B,1,H,W)
            diff = nn.functional.interpolate(diff, size=img.shape[2:], mode="bilinear")
            score_maps.append(diff)

        anomaly = torch.mean(torch.stack(score_maps), dim=0)
        return anomaly

    epochs = 50
    global_step = 0

    for epoch in range(epochs):
        student_model.train()
        for imgs, _ in train_loader:  # train_loader: åªå«æ­£å¸¸æ¨£æœ¬
            imgs = imgs.to(device)

            with torch.no_grad():
                teacher_feats = get_embeddings(teacher_model, imgs)

            student_feats = get_embeddings(student_model, imgs)

            loss = rd4ad_loss(teacher_feats, student_feats, cos)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # log to TensorBoard
            writer.add_scalar("Train/Loss", loss.item(), global_step)
            global_step += 1

        print(f"Epoch [{epoch+1}/{epochs}] Loss: {loss.item():.4f}")

        # === é©—è­‰ ===
        student_model.eval()
        with torch.no_grad():
            val_imgs, _ = next(iter(val_loader))  # val_loader: å«æ­£å¸¸+ç•°å¸¸
            val_imgs = val_imgs.to(device)

            anomaly = anomaly_map(val_imgs)

            # log åŸåœ– & anomaly map
            writer.add_images("Val/Input", val_imgs, epoch)
            writer.add_images("Val/AnomalyMap", (anomaly - anomaly.min()) / (anomaly.max() - anomaly.min() + 1e-8), epoch)

    writer.close()


    print("è¨“ç·´å®Œæˆï¼")  # è¨“ç·´çµæŸ

if __name__ == '__main__':
    import argparse
    import pandas as pd
    import os
    import torch

    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser()
    parser.add_argument('--category', default='bottle', type=str)  # è¨“ç·´é¡åˆ¥
    parser.add_argument('--epochs', default=25, type=int)  # è¨“ç·´å›åˆæ•¸
    parser.add_argument('--arch', default='wres50', type=str)  # æ¨¡å‹æ¶æ§‹
    parser.add_argument('--bs', action='store', type=int, required=True)
    parser.add_argument('--lr', action='store', type=float, required=True)

    args = parser.parse_args()

    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    save_pth_path = f"pths/best_{args.arch}_{args.category}"

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    save_pth_dir = save_pth_path if save_pth_path else 'pths/best'
    os.makedirs(save_pth_dir, exist_ok=True)

    # é–‹å§‹è¨“ç·´ï¼Œä¸¦æ¥æ”¶æœ€ä½³æ¨¡å‹è·¯å¾‘èˆ‡çµæœ
    train(args.arch, args.category, args.epochs, save_pth_path)
